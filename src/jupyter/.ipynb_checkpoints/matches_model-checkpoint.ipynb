{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-57dfa3e47064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# import sklearn modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# import basic modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# import sklearn modules\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# load preprocessed file of match rounds\n",
    "preprocessed_path_file = \"../../data/rounds_preprocessed.csv\"\n",
    "df_matches = pd.read_csv(preprocessed_path_file, encoding='utf_16', index_col=0)\n",
    "\n",
    "# remove matches from the first 4 rounds, there is no enough history for them\n",
    "df_matches = df_matches[df_matches[\"rodada_id\"]>4]\n",
    "\n",
    "df_matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and targets and target for classification\n",
    "# unselected features: 'clube_id', 'placar', 'placar_adv', 'rodada_id',\n",
    "X_col_select = ['in_pos', 'in_pos_adv', 'wins', 'losses', 'draws', \n",
    "                'wins_adv', 'losses_adv', 'draws_adv', 'home']\n",
    "X = df_matches[X_col_select].copy()\n",
    "\n",
    "\n",
    "# adjust scale from numeric features\n",
    "scaler = MinMaxScaler()\n",
    "X['n_in_pos'] = scaler.fit_transform(X[['in_pos']])\n",
    "X['n_in_pos_adv'] = scaler.fit_transform(X[['in_pos_adv']])\n",
    "\n",
    "# remove features adjusted\n",
    "X_col_select = ['n_in_pos', 'n_in_pos_adv', 'wins', 'losses', 'draws', \n",
    "                'wins_adv', 'losses_adv', 'draws_adv', 'home']\n",
    "X = X[X_col_select]\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boolean targets for classification\n",
    "y_col_select = ['result', 'placar', 'placar_adv']\n",
    "y = df_matches[y_col_select].copy()\n",
    "\n",
    "# team lost the match\n",
    "y[\"loss\"] = y[\"result\"].values == \"d\" \n",
    "\n",
    "# team won the match\n",
    "y[\"win\"] = y[\"result\"].values == \"v\"\n",
    "\n",
    "# team suffered zero goals on the match\n",
    "y[\"suffer_zero\"] = y[\"placar_adv\"] == 0\n",
    "\n",
    "# team scored more than 2 goal on the match\n",
    "y[\"scor2plus\"] = y[\"placar\"] > 2\n",
    "\n",
    "# remove original values\n",
    "y = y.drop(['result', 'placar', 'placar_adv'], axis=1)\n",
    "\n",
    "# first select a model for the win target, using recall_score to minimize false positive\n",
    "ya = y[\"win\"].values.ravel()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "print(X.info(), ya.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = KNeighborsClassifier()\n",
    "param_dict = {\"n_neighbors\": [2, 5, 10, 15],\n",
    "             \"algorithm\": ['ball_tree', 'kd_tree'],\n",
    "             \"weights\": ['uniform', 'distance']}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=est, param_distributions=param_dict, scoring=scorer,\n",
    "                        n_iter=16, cv=50, random_state=1984)\n",
    "rs.fit(X, ya)\n",
    "\n",
    "print(\"KNN - best recall score = %.3f\"%rs.best_score_)\n",
    "print(\"KNN - best params = \",rs.best_params_)\n",
    "print(\"KNN - mean recall score = %.3f\"%rs.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = DecisionTreeClassifier()\n",
    "param_dict = {\"max_depth\": [5, 10, 20, 30],\n",
    "             \"min_samples_leaf\": [1, 3, 5],\n",
    "             \"max_features\": [2, 3, 5, 9]} #'auto', 'sqrt', 'log2']}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=est, param_distributions=param_dict, scoring=scorer,\n",
    "                        n_iter=48, cv=50, random_state=1984)\n",
    "rs.fit(X, ya)\n",
    "\n",
    "print(\"DecisionTree - best recall score = %.3f\"%rs.best_score_)\n",
    "print(\"DecisionTree - best params = \",rs.best_params_)\n",
    "print(\"DecisionTree - mean recall score = %.3f\"%rs.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(max_features=9, max_depth=5)\n",
    "param_dict = {\"n_estimators\": [50, 100, 200],\n",
    "              #\"max_depth\": [20, 30, 40],\n",
    "             \"min_samples_leaf\": [1, 3, 5]}#,\n",
    "             #\"max_features\": [2, 5, 7]} \n",
    "\n",
    "rs = RandomizedSearchCV(estimator=est, param_distributions=param_dict, scoring=scorer,\n",
    "                        n_iter=9, cv=50, random_state=1984)\n",
    "time = timeit.timeit()\n",
    "rs.fit(X, ya)\n",
    "print(\"DecisionTree - fit ellapsed time = %.3f seconds\"%(time-timeit.timeit()))\n",
    "\n",
    "print(\"RandomForest - best recall score = %.3f\"%rs.best_score_)\n",
    "print(\"RandomForest - best params = \",rs.best_params_)\n",
    "print(\"RandomForest - mean recall score = %.3f\"%rs.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = MultinomialNB()\n",
    "param_dict = {\"alpha\": [0, 0.5, 1]} \n",
    "\n",
    "rs = RandomizedSearchCV(estimator=est, param_distributions=param_dict, scoring=scorer,\n",
    "                        n_iter=2, cv=5, random_state=1984)\n",
    "time = timeit.timeit()\n",
    "rs.fit(X, ya)\n",
    "print(\"Naive Bayes - fit ellapsed time = %.3f seconds\"%(time-timeit.timeit()))\n",
    "\n",
    "print(\"Naive Bayes - best recall score = %.3f\"%rs.best_score_)\n",
    "print(\"Naive Bayes - best params = \",rs.best_params_)\n",
    "print(\"Naive Bayes - mean recall score = %.3f\"%rs.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LogisticRegression()\n",
    "param_dict = {\"C\": [.1, 1, 5, 10]} \n",
    "\n",
    "rs = RandomizedSearchCV(estimator=est, param_distributions=param_dict, scoring=scorer,\n",
    "                        n_iter=4, cv=50, random_state=1984)\n",
    "time = timeit.timeit()\n",
    "rs.fit(X, ya)\n",
    "print(\"LogisticRegression - fit ellapsed time = %.3f seconds\"%(time-timeit.timeit()))\n",
    "\n",
    "print(\"LogisticRegression - best recall score = %.3f\"%rs.best_score_)\n",
    "print(\"LogisticRegression - best params = \",rs.best_params_)\n",
    "print(\"LogisticRegression - mean recall score = %.3f\"%rs.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
